{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from helpers import correct_token, generate_n_gram, to_ngram, align_sequences, glue_sequence, display_match\n",
    "from nltk import word_tokenize\n",
    "SC = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model parameters\n",
    "ENG_STOPWORDS = set(stopwords.words(\"english\"))\n",
    "N_GRAM = 3\n",
    "GAP_TOLERANCE = 5 \n",
    "PADDING = 20\n",
    "\n",
    "\n",
    "def treat_article(article_path:str, context, stopwords, n):\n",
    "    with open(article_path, mode = \"r\", encoding = \"utf-8\") as f:\n",
    "        data = ''.join(f.readlines())\n",
    "    full_article = ''.join([c for c in data if c.isalnum() or c == \" \"])\n",
    "    tokenized_article = list(enumerate(word_tokenize(full_article)))\n",
    "    filtered_article = [(index,token.lower()) for index,token in tokenized_article if token not in stopwords ]\n",
    "    filtered_indexes = [index for index,_ in filtered_article]\n",
    "    corrected_article = context.parallelize(filtered_article).map(lambda x: x[1]).map(correct_token).collect()\n",
    "    corrected_article = list(zip(filtered_indexes, corrected_article))\n",
    "    n_grams = list(generate_n_gram(corrected_article, n))\n",
    "    n_gram_dict =defaultdict(list)\n",
    "    for n_gram in n_grams:\n",
    "        n_gram_dict[to_ngram(n_gram)].append(n_gram[0][0])\n",
    "    return tokenized_article, n_gram_dict\n",
    "\n",
    "def compute_plagiarism(art_1_path: str, art_2_path: str):\n",
    "\n",
    "    # First treat the articles \n",
    "    treated_1, grams_1 = treat_article(art_1_path, SC, ENG_STOPWORDS, N_GRAM)\n",
    "    treated_2, grams_2 = treat_article(art_2_path, SC, ENG_STOPWORDS, N_GRAM)\n",
    "\n",
    "    # Align sequence and glue the sequences \n",
    "    matching_sequence = align_sequences(grams_1,grams_2)\n",
    "    glued_sequence = glue_sequence(matching_sequence, GAP_TOLERANCE)\n",
    "\n",
    "    # Create the viewer function \n",
    "    match_viewer = lambda i: display_match(glued_sequence[i], treated_1,treated_2, PADDING)\n",
    "\n",
    "    # compute the plagiarism score from both articles\n",
    "    score = 2*len(matching_sequence)/(len(treated_1) + len(treated_2)) * 100\n",
    "\n",
    "    print(\"The two articles have a similarity score of {:.2f}, with {} matching n-gram. You can use the viewer to visualize the matching sequences\".format(score, len(matching_sequence)))\n",
    "    return match_viewer, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two articles have a similarity score of 1.31, with 81 matching n-gram. You can use the viewer to visualize the matching sequences\n"
     ]
    }
   ],
   "source": [
    "### File paths \n",
    "fr_path = \"./txt files/french.txt\"\n",
    "en_path = \"./txt files/english.txt\"\n",
    "it_path = \"./txt files/italian.txt\"\n",
    "es_path = \"./txt files/spanish.txt\"\n",
    "\n",
    "viewer , score = compute_plagiarism(fr_path, en_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Cross gold at eight spikes having of one side one is the only leader first president born but he dove \u001b[31mdove enamelled in\u001b[0m in white on the other the image not there seldom afflicts from there come that there is Saint Michael Orals make\n",
      "and the cross eight pointed gold on one side with a war council so much so that the first king dove \u001b[31mdove enamelled in\u001b[0m in white and on the other the im sta in charge of all the active part and performance of S Michele\n"
     ]
    }
   ],
   "source": [
    "viewer(36)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('p38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c08fb7d0681ab80e3191df3cdd3d9ae56e033f792b7fa01572cc6446116ecae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
